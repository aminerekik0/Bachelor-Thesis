{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53fb95e",
   "metadata": {},
   "source": [
    "Evaluation of our Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5f0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoreload enabled.\n",
      "Current notebook directory: c:\\Users\\I7- 9700\\rekik-BA\\Bachelor-Thesis\\experiments\\framework_eval\n",
      "Calculated project root: c:\\Users\\I7- 9700\\rekik-BA\\Bachelor-Thesis\n",
      "Target 'src' directory: c:\\Users\\I7- 9700\\rekik-BA\\Bachelor-Thesis\\src\n",
      "Added to path: c:\\Users\\I7- 9700\\rekik-BA\\Bachelor-Thesis\\src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\I7- 9700\\rekik-BA\\Bachelor-Thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imports loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# --- 1. IPython Magic: Autoreload ---\n",
    "# This tells the notebook to automatically reload modules\n",
    "# when the .py files (like LinearMetaModel.py) are changed.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(\"Autoreload enabled.\")\n",
    "\n",
    "# --- 2. Setup Paths ---\n",
    "# Get the current directory of the notebook (e.g., .../Bachelor-Thesis/experiments/framework_eval)\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current notebook directory: {current_dir}\")\n",
    "\n",
    "# Go UP TWO levels to the project root (e.g., .../Bachelor-Thesis)\n",
    "project_root = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir))\n",
    "print(f\"Calculated project root: {project_root}\")\n",
    "\n",
    "# Define the correct path to the 'src' folder (e.g., .../Bachelor-Thesis/src)\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "print(f\"Target 'src' directory: {src_path}\")\n",
    "\n",
    "# Add the correct 'src' path\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    print(f\"Added to path: {src_path}\")\n",
    "else:\n",
    "    print(f\"Path already exists: {src_path}\")\n",
    "\n",
    "# --- 3. Try imports ---\n",
    "# This cell should now work, BUT only if you do Part 2 below\n",
    "try:\n",
    "    from ExplainableTreeEnsemble import ExplainableTreeEnsemble\n",
    "    from BasicMetaModel import BasicMetaModel\n",
    "    from LinearMetaModel import LinearMetaModel\n",
    "    print(\"\\nImports loaded successfully.\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"\\nImport Error: {e}\")\n",
    "    print(f\"Could not find modules at: {src_path}\")\n",
    "    print(\">>> IF THIS FAILED, PLEASE DO PART 2 <<<\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Experiment ---\n",
      "Dataset: slice\n",
      "Stage 1 Keep Ratio: 0.3\n",
      "Stage 2 Corr Thresh: 0.95\n",
      "Results will be saved to: framework_analysis_results.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Define Experiment Parameters ---\n",
    "DATASET_NAME = \"3droad\"\n",
    "KEEP_RATIO_STAGE1 = 0.3  # 200 trees -> 60 trees (30%)\n",
    "\n",
    "# Set dynamic correlation threshold\n",
    "if DATASET_NAME == \"bike\":\n",
    "    CORR_THRESH_STAGE2 = 0.99\n",
    "elif DATASET_NAME == \"3droad\":\n",
    "    CORR_THRESH_STAGE2 = 0.9\n",
    "elif DATASET_NAME == \"slice\":\n",
    "    CORR_THRESH_STAGE2 = 0.95\n",
    "else:\n",
    "    CORR_THRESH_STAGE2 = 0.9\n",
    "\n",
    "# This is the file we will append to\n",
    "output_file = \"framework_analysis_results.csv\"\n",
    "\n",
    "print(f\"--- Starting Experiment ---\")\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Stage 1 Keep Ratio: {KEEP_RATIO_STAGE1}\")\n",
    "print(f\"Stage 2 Corr Thresh: {CORR_THRESH_STAGE2}\")\n",
    "print(f\"Results will be saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8116a033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1/3] Training Full Ensemble...\n",
      "slice dataset, N=53500, d=385\n",
      "-------------creating the base Trees-------------- \n",
      "full ensemble mse 74.3770295084585\n",
      "Full Ensemble: 74.3770 MSE, 200 Trees\n",
      "Dataset Stats: 42800 samples, 385 features\n",
      "\n",
      "'workflow' object created.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Step 1: Full Ensemble (Baseline) ---\n",
    "print(\"\\n[Step 1/3] Training Full Ensemble...\")\n",
    "\n",
    "# Assumes Cell 2 has been run\n",
    "workflow = ExplainableTreeEnsemble(data_type=\"regression\", dataset_name=DATASET_NAME)\n",
    "workflow.train_base_trees()\n",
    "\n",
    "# FIX: We manually call _evaluate() to get the MSE\n",
    "mse_full, _ , _ , _ , _ ,  _ = workflow._evaluate()\n",
    "trees_full = workflow.n_trees\n",
    "\n",
    "# Get n_samples and n_features from the workflow\n",
    "n_samples = workflow.n_samples\n",
    "n_features = workflow.n_features\n",
    "\n",
    "print(f\"Full Ensemble: {mse_full:.4f} MSE, {trees_full} Trees\")\n",
    "print(f\"Dataset Stats: {n_samples} samples, {n_features} features\")\n",
    "print(\"\\n'workflow' object created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f885cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2/3] Running Stage 1 (SHAP Rank Pruning)...\n",
      "=== Stage 1: Training model and pruning by SHAP (keep top 30.0%) ===\n",
      "Pre-Pruned ensemble MSE (Weighted): 44.575492343061676\n",
      "After Stage 1: 44.5755 MSE, 60 Trees\n",
      "\n",
      "'model_stage1' object created.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Step 2: Stage 1 Pruning (SHAP Rank) ---\n",
    "print(\"\\n[Step 2/3] Running Stage 1 (SHAP Rank Pruning)...\")\n",
    "\n",
    "try:\n",
    "    model_stage1 = BasicMetaModel(keep_ratio=KEEP_RATIO_STAGE1)\n",
    "    model_stage1.attach_to(workflow)\n",
    "    model_stage1.train() \n",
    "\n",
    "    mse_stage1, _ = model_stage1.evaluate() \n",
    "    trees_stage1 = len(model_stage1.pruned_trees)\n",
    "\n",
    "    print(f\"After Stage 1: {mse_stage1:.4f} MSE, {trees_stage1} Trees\")\n",
    "    print(\"\\n'model_stage1' object created.\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"Error: Make sure you have run Cell 3 first! (Details: {e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4692192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3/3] Running Stage 2 (HRP Optimization Pruning)...\n",
      "[INFO] Training LinearMetaModel on 60 pruned trees...\n",
      " Lambda prune :  158.97283935546875\n",
      " Lambda div :  79.48641967773438\n",
      "Epoch    0 | Total Loss: 1189.1631 | MSE Loss: 593.5637 | Prune Loss: 3.7337 | Div Loss: 0.025611\n",
      "Epoch   20 | Total Loss: 646.2557 | MSE Loss: 61.9592 | Prune Loss: 3.6614 | Div Loss: 0.028024\n",
      "Epoch   40 | Total Loss: 587.4935 | MSE Loss: 33.9893 | Prune Loss: 3.4646 | Div Loss: 0.034313\n",
      "Epoch   60 | Total Loss: 548.8109 | MSE Loss: 30.8708 | Prune Loss: 3.2364 | Div Loss: 0.043354\n",
      "Epoch   80 | Total Loss: 520.8850 | MSE Loss: 29.6153 | Prune Loss: 3.0635 | Div Loss: 0.053542\n",
      "Epoch  100 | Total Loss: 497.2164 | MSE Loss: 28.7824 | Prune Loss: 2.9142 | Div Loss: 0.064812\n",
      "Epoch  120 | Total Loss: 472.2151 | MSE Loss: 28.9088 | Prune Loss: 2.7498 | Div Loss: 0.077582\n",
      "Epoch  140 | Total Loss: 452.6099 | MSE Loss: 28.6007 | Prune Loss: 2.6212 | Div Loss: 0.091959\n",
      "Epoch  160 | Total Loss: 434.9897 | MSE Loss: 29.7071 | Prune Loss: 2.4938 | Div Loss: 0.111072\n",
      "Epoch  180 | Total Loss: 403.0699 | MSE Loss: 31.6610 | Prune Loss: 2.2668 | Div Loss: 0.139056\n",
      "Epoch  199 | Total Loss: 388.7631 | MSE Loss: 33.3222 | Prune Loss: 2.1567 | Div Loss: 0.158402\n",
      "[INFO] LinearMetaModel training complete. Final loss: 388.7631\n",
      "[INFO] Pruning 60 trees...\n",
      "[INFO] Stage 1 (Weight): Kept 25 / 60 trees.\n",
      "[INFO] Stage 2 (Correlation): Checking 25 trees for correlation > 0.95...\n",
      "[INFO] Stage 2 (Correlation): Removed 2 redundant trees.\n",
      "[INFO] Final ensemble size: 23\n",
      "[INFO] Re-training final model on pruned set to get evaluation weights...\n",
      "[INFO] Final Ensemble Pruned MSE (Weighted): 32.7935\n",
      "After Stage 2: 32.7935 MSE, 23 Trees\n",
      "\n",
      "'model_stage2' object created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n[Step 3/3] Running Stage 2 (HRP Optimization Pruning)...\")\n",
    "\n",
    "try:\n",
    "    model_stage2 = LinearMetaModel()\n",
    "    model_stage2.attach_to(workflow) \n",
    "    model_stage2.train(pruned_trees_list=model_stage1.pruned_trees) \n",
    "    model_stage2.prune(corr_thresh=CORR_THRESH_STAGE2) \n",
    "\n",
    "    mse_stage2, _ = model_stage2.evaluate() \n",
    "    trees_stage2 = len(model_stage2.pruned_trees)\n",
    "\n",
    "    print(f\"After Stage 2: {mse_stage2:.4f} MSE, {trees_stage2} Trees\")\n",
    "    print(\"\\n'model_stage2' object created.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: Make sure you have run Cell 4 first! (Details: {e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d9708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Experiment Complete ---\n",
      "File 'framework_analysis_results.csv' exists. Appending new result.\n",
      "\n",
      "Results successfully saved to framework_analysis_results.csv\n",
      "\n",
      "--- Current CSV Content ---\n",
      "   dataset_name  n_samples  n_features    mse_full  mse_stage1  mse_stage2\n",
      "0        3droad     347899           3  179.982272  148.960932  120.475382\n",
      "1         slice      42800         385   70.161952   42.605203   35.568698\n",
      "2         slice      42800         385   72.385460   46.575549   36.227354\n",
      "3         slice      42800         385   62.305534   38.554120   25.425535\n",
      "4         slice      42800         385   62.311290   46.294762   30.395166\n",
      "5         slice      42800         385   62.311290   46.294762   30.748182\n",
      "6         slice      42800         385   64.157213   41.450804   31.294830\n",
      "7         slice      42800         385   75.593464   49.212943   41.603926\n",
      "8         slice      42800         385   69.244611   52.208408   40.333366\n",
      "9         slice      42800         385   61.272665   38.961108   36.001543\n",
      "10        slice      42800         385   68.708253   39.319297   35.629533\n",
      "11        slice      42800         385   75.554511   35.145439   34.174015\n",
      "12        slice      42800         385   73.196921   45.244547   30.073106\n",
      "13        slice      42800         385   74.377030   44.575492   32.793482\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Collect and Append Results to CSV ---\n",
    "print(\"\\n--- Experiment Complete ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Create a dictionary for the new result row\n",
    "    new_result = {\n",
    "        \"dataset_name\": DATASET_NAME,\n",
    "        \"n_samples\": n_samples,\n",
    "        \"n_features\": n_features,\n",
    "        \"mse_full\": mse_full,\n",
    "        \"mse_stage1\": mse_stage1,\n",
    "        \"mse_stage2\": mse_stage2\n",
    "    }\n",
    "    \n",
    "    # 2. Convert new result to a DataFrame\n",
    "    df_new = pd.DataFrame([new_result])\n",
    "\n",
    "    # 3. Check if the file already exists\n",
    "    if os.path.exists(output_file):\n",
    "        # File exists: Append without header\n",
    "        print(f\"File '{output_file}' exists. Appending new result.\")\n",
    "        df_new.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        # File does not exist: Create it and write with header\n",
    "        print(f\"File '{output_file}' not found. Creating new file.\")\n",
    "        df_new.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "    print(f\"\\nResults successfully saved to {output_file}\")\n",
    "    \n",
    "    # 4. Display the full CSV content\n",
    "    print(\"\\n--- Current CSV Content ---\")\n",
    "    print(pd.read_csv(output_file))\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: A variable is missing! Make sure you have run Cells 2-5 first. (Details: {e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8b9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
